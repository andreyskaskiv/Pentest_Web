#!/usr/bin/python

import re
import urllib.parse

import requests


def extract_links_from(target_url: str):
    """Extract links from the target site using regular expressions"""
    response = requests.get(target_url)
    return re.findall('(?:href=")(.*?)"', response.content.decode())


def get_links(target_url: str, links: list[str]):
    """Link Refactor. Removes duplicates. Removes links not related to the target site."""
    target_links = []

    for link in links:
        link = urllib.parse.urljoin(target_url, link)

        if "#" in link:
            link = link.split("#")[0]

        if target_url in link and link not in target_links:
            target_links.append(link)
            print(link)

    return target_links


def main(target_url: str):
    """Main controller"""
    href_links = extract_links_from(target_url)
    links_on_the_target_site = get_links(target_url, href_links)
    # print(links_on_the_target_site)


if __name__ == '__main__':
    """Don't forget to replace http with https"""

    # url = "http://10.0.2.12"
    url = "http://10.0.2.12/mutillidae/"
    main(url)
