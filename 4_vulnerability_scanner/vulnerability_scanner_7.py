import re
import urllib.parse
import urllib.parse as urlparse

import requests
from bs4 import BeautifulSoup
from colorama import init, Fore, Style

from handlers.decode_handler import decode_values


class Scanner:
    def __init__(self, url: str, ignore_links: list[str]):
        """
        :param url: target url
        :param ignore_links: a list with ignored links, for example, so as not to lose the session
        """
        init()
        self.session = requests.Session()
        self.target_url = url
        self.target_links = []
        self.ignore_links = ignore_links

    def extract_links_from(self, url: str):
        """Extract links from the target site using regular expressions"""
        response = self.session.get(url)
        answer = decode_values(response.content)
        return re.findall('(?:href=")(.*?)"', answer)

    def crawl(self, url=None):
        """Link Refactor. Removes duplicates. Removes links not related to the target site."""
        if url is None:
            url = self.target_url

        href_links = self.extract_links_from(url)
        for link in href_links:
            link = urllib.parse.urljoin(url, link)

            if "#" in link:
                link = link.split("#")[0]

            if (self.target_url in link
                    and link not in self.target_links
                    and link not in self.ignore_links):
                self.target_links.append(link)
                print(link)

                self.crawl(link)

    def extract_forms(self, url: str):
        """This function is used to extract all the forms from a webpage specified by the input URL."""
        response = self.session.get(url)
        parsed_html = BeautifulSoup(response.content, features='lxml')  # features='html.parser' features='lxml'
        return parsed_html.findAll("form")

    def submit_form(self, form, value: dict | str, url: str):
        """
        Extract all required attributes from forms. Fill out and submit the form
        :param form: Specify the form you want to submit
        :param value: The value we want to set for the inputs in this form
        :param url: Url address of the page from which we retrieved this form
        :return:
        """

        action = form.get("action")
        post_url = urlparse.urljoin(url, action)
        method = form.get("method")

        inputs_list = form.findAll("input")

        post_data = {}
        for input in inputs_list:
            input_name = input.get("name")
            input_type = input.get("type")
            input_value = input.get("value")
            if input_type == "text":
                input_value = value

            post_data[input_name] = input_value

        if method == 'post':
            return self.session.post(post_url, data=post_data)
        return self.session.get(post_url, params=post_data)

    def run_scanner(self):
        """Check each link in the target_links list, extract forms from those links.
         Check forms and links for vulnerabilities"""
        for link in self.target_links:
            forms = self.extract_forms(link)

            for form in forms:
                """Add and call a method if a FORM vulnerability is found"""
                print(f"[+] ðŸ’£ Testing form in: {link}")
                is_vulnerable_to_xss = self.test_xss_in_form(form=form, url=link)
                if is_vulnerable_to_xss:
                    print(f"\n{Fore.CYAN}[***] XSS Discovered in: {link}{Style.RESET_ALL}\n")
                    print(f"{Fore.GREEN}Form: {Style.RESET_ALL} \n{form}")
                    print("=" * 50)

            if "=" in link:
                """Add and call a method if a LINK vulnerability is found"""
                print(f"[+] ðŸ’£ Testing Link: {link}")
                is_vulnerable_to_xss = self.test_xss_in_link(link)
                if is_vulnerable_to_xss:
                    print(f"\n{Fore.YELLOW}[***] XSS Discovered in: {link}{Style.RESET_ALL}\n")

    def test_xss_in_form(self, form, url: str):
        """This method is used to check xxs vulnerabilities in forms"""
        xss_payload = "<sCript>alert('XSS PAYLOAD form')</scriPt>"
        response = self.submit_form(form=form, value=xss_payload, url=url)
        return xss_payload in response.text

    def test_xss_in_link(self, url: str):
        """This method is used to check xxs vulnerabilities in links"""
        xss_payload = "<sCript>alert('XSS PAYLOAD link')</scriPt>"
        url = url.replace("=", f"={xss_payload}")
        response = self.session.get(url=url)
        return xss_payload in response.text


if __name__ == '__main__':
    # target_url = "http://10.0.2.12/mutillidae/"
    target_url = "http://10.0.2.12/dvwa/"
    login = f"{target_url}/login.php"

    links_to_ignore = [
        'http://10.0.2.12/dvwa/logout.php'
    ]

    data_dict = {
        "username": 'admin',
        "password": 'password',
        "Login": 'submit',
    }

    vulnerability_scanner = Scanner(target_url, links_to_ignore)

    # Authorization and session creation
    vulnerability_scanner.session.post(login, data=data_dict)

    # At the beginning we start the collector of all links
    print("\033[1;32m\n\nCrawler Starts ðŸ§ ==> \033[0m")
    vulnerability_scanner.crawl()

    # Then run the vulnerability scanner
    print("\033[1;32m\n\nVulnerability Scanner Starts ðŸ§ ==> \033[0m")
    vulnerability_scanner.run_scanner()
