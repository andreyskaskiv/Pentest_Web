#!/usr/bin/python

import urllib.parse as urlparse

import requests
from bs4 import BeautifulSoup


def extract_forms(url: str):
	"""This function is used to extract all the forms from a webpage specified by the input URL."""
	response = requests.get(url)
	parsed_html = BeautifulSoup(response.content, features='lxml')  # features='html.parser' features='lxml'
	return parsed_html.findAll("form")


def form_fields_extraction(forms_list: list, url: str):
	"""Extract all necessary attributes from the form"""
	for form in forms_list:
		action = form.get("action")
		method = form.get("method")
		post_url = urlparse.urljoin(url, action)

		inputs_list = form.findAll("input")

		post_data = {}
		for input in inputs_list:
			input_name = input.get("name")
			input_type = input.get("type")
			input_value = input.get("value")
			if input_type == "text":
				input_value = "test"

			post_data[input_name] = input_value

		print(post_data)
		result = requests.post(post_url, data=post_data)
		# print(result.content.decode())
		if "Results for test" in result.content.decode():
			print("[+] Success !!!")


def main(url: str, ):
	forms_list = extract_forms(url)
	form_fields_extraction(forms_list, url)


if __name__ == '__main__':
	target_url = "http://10.0.2.12/mutillidae/index.php?page=dns-lookup.php"

	main(target_url)
