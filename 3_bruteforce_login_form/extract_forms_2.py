#!/usr/bin/python

import urllib.parse as urlparse

import requests
from bs4 import BeautifulSoup


def extract_forms(url: str):
	"""This function is used to extract all the forms from a webpage specified by the input URL."""
	response = requests.get(url)
	parsed_html = BeautifulSoup(response.content, features='lxml')  # features='html.parser' features='lxml'
	return parsed_html.findAll("form")


def form_fields_extraction(forms_list: list, url: str):
	"""Extract all necessary attributes from the form"""
	for form in forms_list:
		action = form.get("action")
		method = form.get("method")
		post_url = urlparse.urljoin(url, action)
		print(f"method: {method}")
		print(f"post_url: {post_url}")

		inputs_list = form.findAll("input")

		for input in inputs_list:
			input_name = input.get("name")
			print(f"Name: {input_name}")


def main(url: str, ):
	forms_list = extract_forms(url)
	form_fields_extraction(forms_list, url)


if __name__ == '__main__':
	target_url = "http://10.0.2.12/mutillidae/index.php?page=dns-lookup.php"

	main(target_url)
