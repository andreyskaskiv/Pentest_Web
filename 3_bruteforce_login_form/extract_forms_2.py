#!/usr/bin/python

import urllib.parse as urlparse

import requests
from bs4 import BeautifulSoup


def extract_forms(url: str):
	"""This function is used to extract all the forms from a webpage specified by the input URL."""
	response = requests.get(url)
	parsed_html = BeautifulSoup(response.content, features='lxml')  # features='html.parser' features='lxml'
	return parsed_html.findAll("form")


def form_fields_extraction(forms_list: list, url: str):
	"""Extract all necessary attributes from the form"""
	for form in forms_list:
		action = form.get("action")
		method = form.get("method")
		post_url = urlparse.urljoin(url, action)
		print(f"method: {method}")
		print(f"post_url: {post_url}")
		print("- " * 20)

		inputs_list = form.findAll("input")
		print(inputs_list)
		print("- " * 20)

		for input in inputs_list:
			input_name = input.get("name")
			input_type = input.get("type")
			input_value = input.get("value")
			print(f"input_name: {input_name}")
			print(f"input_type: {input_type}")
			print(f"input_value: {input_value}")
			print("* " * 3)


def main(url: str, ):
	forms_list = extract_forms(url)
	form_fields_extraction(forms_list, url)


if __name__ == '__main__':
	# target_url = "http://10.0.2.12/mutillidae/index.php?page=dns-lookup.php"
	target_url = "http://10.0.2.12/dvwa/login.php"

	main(target_url)
